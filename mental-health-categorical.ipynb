{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7872606,"sourceType":"datasetVersion","datasetId":4619539}],"dockerImageVersionId":30357,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sebastinconcha/mental-health-categorical?scriptVersionId=186599817\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-02T23:44:13.440412Z","iopub.execute_input":"2024-07-02T23:44:13.440926Z","iopub.status.idle":"2024-07-02T23:44:13.455504Z","shell.execute_reply.started":"2024-07-02T23:44:13.440887Z","shell.execute_reply":"2024-07-02T23:44:13.453605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Importar librerias / Import libraries\n\n# Saltaremos los warnings / skip the code warnings\nimport warnings\nwarnings.filterwarnings('ignore', category=UserWarning)\n\nimport tensorflow as tf\n\nfrom keras import Sequential, Input\nfrom keras.layers import Dense\n\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss, recall_score\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB","metadata":{"execution":{"iopub.status.busy":"2024-07-02T23:44:15.341854Z","iopub.execute_input":"2024-07-02T23:44:15.343157Z","iopub.status.idle":"2024-07-02T23:44:23.560569Z","shell.execute_reply.started":"2024-07-02T23:44:15.343092Z","shell.execute_reply":"2024-07-02T23:44:23.558847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Configuracion de Panda / Pandas Configuration\npd.set_option('display.max_columns', None)\n\n# Definimos el dataset y lo grabamos en variable \"df\" / Define dataset and save it into variable called \"df\":\ndf = pd.read_csv(\"/kaggle/input/mental-health-dataset/Mental Health Dataset.csv\")\n\n# Revisar rápidamente los elementos del dataframe / Quickyl check the elements of the dataframe\ndf.head(5)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T23:44:26.245827Z","iopub.execute_input":"2024-07-02T23:44:26.246747Z","iopub.status.idle":"2024-07-02T23:44:27.48808Z","shell.execute_reply.started":"2024-07-02T23:44:26.246703Z","shell.execute_reply":"2024-07-02T23:44:27.486793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Se revisará más información del data frame / Check for extra info of the DF\nprint(df.info())","metadata":{"execution":{"iopub.status.busy":"2024-07-01T16:04:12.819075Z","iopub.execute_input":"2024-07-01T16:04:12.819686Z","iopub.status.idle":"2024-07-01T16:04:13.097787Z","shell.execute_reply.started":"2024-07-01T16:04:12.819634Z","shell.execute_reply":"2024-07-01T16:04:13.096333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Se dropearán los valores NA, debido a que representan un porcentaje ínfimo al total (1.78%)\n# Drop NA values, as they are only 5202 from the main set (1.78%)\ndf.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T23:44:31.571221Z","iopub.execute_input":"2024-07-02T23:44:31.571667Z","iopub.status.idle":"2024-07-02T23:44:32.237604Z","shell.execute_reply.started":"2024-07-02T23:44:31.57163Z","shell.execute_reply":"2024-07-02T23:44:32.235911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Se dropea la columna de timestamp, ya que no nos interesa el valor de tiempo\n# Dropping TIMESTAMP as we are not interested in the time of recording (only a two year range)\ndf.drop(labels= 'Timestamp', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T23:44:32.922117Z","iopub.execute_input":"2024-07-02T23:44:32.92263Z","iopub.status.idle":"2024-07-02T23:44:33.020414Z","shell.execute_reply.started":"2024-07-02T23:44:32.92259Z","shell.execute_reply":"2024-07-02T23:44:33.018991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Aplicamos onehoteencoding, para que nuestros atributos obtengan valores categoricos\n# Applying ONEHOTENCODING (OHE) in categorical features\ndf_ohe = pd.get_dummies(df, columns = ['Growing_Stress', 'care_options', 'Country', 'Gender','Occupation', 'Changes_Habits', 'Mental_Health_History', 'Work_Interest', 'Mood_Swings', 'Social_Weakness', 'mental_health_interview', 'Days_Indoors'])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T23:44:34.804222Z","iopub.execute_input":"2024-07-02T23:44:34.80524Z","iopub.status.idle":"2024-07-02T23:44:35.520175Z","shell.execute_reply.started":"2024-07-02T23:44:34.805146Z","shell.execute_reply":"2024-07-02T23:44:35.518618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convertimos los atributos que nos faltan también en valores categoricos. True o \"Yes\" se convierte en 1. False o \"No\" se convierte en 0.\n# Then convert the True or 'Yes' options to 1, and False or 'No' to 0 with a boolean mapping.\nboolean_mapping = {False: 0, True: 1, 'No': 0, 'Yes': 1}\ndf_BM = df_ohe.applymap(lambda x: boolean_mapping.get(x))","metadata":{"execution":{"iopub.status.busy":"2024-07-02T23:44:36.511982Z","iopub.execute_input":"2024-07-02T23:44:36.513047Z","iopub.status.idle":"2024-07-02T23:44:53.733729Z","shell.execute_reply.started":"2024-07-02T23:44:36.513001Z","shell.execute_reply":"2024-07-02T23:44:53.732139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Revision rapida de nuestro dataframe hasta ahora / Quick review of our dataframe so far\ndf_BM.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T16:15:45.914336Z","iopub.execute_input":"2024-07-01T16:15:45.914891Z","iopub.status.idle":"2024-07-01T16:15:45.965138Z","shell.execute_reply.started":"2024-07-01T16:15:45.91483Z","shell.execute_reply":"2024-07-01T16:15:45.963893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separamos atributos y resultados\n# Define X(features) and Y(results)\ny = df_BM.pop('treatment')\nX = df_BM","metadata":{"execution":{"iopub.status.busy":"2024-07-02T23:44:53.736177Z","iopub.execute_input":"2024-07-02T23:44:53.736608Z","iopub.status.idle":"2024-07-02T23:44:53.744909Z","shell.execute_reply.started":"2024-07-02T23:44:53.736569Z","shell.execute_reply":"2024-07-02T23:44:53.742894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Obtenemos numero de columnas\n# Number of columns\nn_cols = X.shape[1]","metadata":{"execution":{"iopub.status.busy":"2024-07-02T23:44:53.746918Z","iopub.execute_input":"2024-07-02T23:44:53.747383Z","iopub.status.idle":"2024-07-02T23:44:53.767965Z","shell.execute_reply.started":"2024-07-02T23:44:53.747346Z","shell.execute_reply":"2024-07-02T23:44:53.766601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separamos el dataset en 80% para entrenar y 20% para probar\n# Splitting the dataset in train and test (80% train and 20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T23:44:55.781595Z","iopub.execute_input":"2024-07-02T23:44:55.782093Z","iopub.status.idle":"2024-07-02T23:44:56.112399Z","shell.execute_reply.started":"2024-07-02T23:44:55.78204Z","shell.execute_reply":"2024-07-02T23:44:56.110885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Antes de hacer un análisis, se haran pruebas sobre los métodos más precisos para este caso particular. Nos enfocaremos en la métrica de recall debido a que nos es más importante detectar los falsos negativos que los falsos positivos, es decir, capturar cuando NO se recomienda un atributo de visita a un centro de salud mental cuando SI es recomendable ir. Las consecuencias pueden ser peores, y en temas de salud se intentará maximizar éste parámetro.**\n\n**Before the actual analysis, we will try different aproaches between Deep Networks and Machine Learning. The focus will be set into the \"recall\" metric, it is far more important for us to detect false negatives than false positives, as in terms of healthcare, we must prioritize and focus in not giving wrong instructions.**","metadata":{}},{"cell_type":"code","source":"# Definimos una metrica de recall customizada (parámetro que nos interesa por sobre la precisión)\n# Custom recall metric \ndef recall(y_true, y_pred):\n    true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1)))\n    possible_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n    return recall\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T16:44:47.277188Z","iopub.execute_input":"2024-07-01T16:44:47.277676Z","iopub.status.idle":"2024-07-01T16:44:47.286552Z","shell.execute_reply.started":"2024-07-01T16:44:47.277637Z","shell.execute_reply":"2024-07-01T16:44:47.284779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Primero se probará lo que es Redes Neuronales\nFirst we will test Deep Neural Network**","metadata":{}},{"cell_type":"code","source":"# Definimos el modelo, optimizando nuestro parámetro de recall lo más posible\n# Define model, optimizing the recall parameter\ndef sequential_testing(units1=16, units2=32, units3=64, optimizer='adam'):\n    model = Sequential()\n    model.add(Input(shape=(n_cols, )))\n    model.add(Dense(units=units1, activation='relu'))\n    model.add(Dense(units=units2, activation='relu'))\n    model.add(Dense(units=units3, activation='relu'))\n    model.add(Dense(units=1, activation='sigmoid'))\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy',recall])\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-07-01T16:52:19.782409Z","iopub.execute_input":"2024-07-01T16:52:19.782901Z","iopub.status.idle":"2024-07-01T16:52:19.792373Z","shell.execute_reply.started":"2024-07-01T16:52:19.782858Z","shell.execute_reply":"2024-07-01T16:52:19.790756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Parámetros que se probarán\n# Parameters for testing\nparameters = {\n    'units1': [8, 16, 32],\n    'units2': [16, 32, 64],\n    'units3': [32, 64, 128],\n    'batch_size': [10, 50, 100, 250, 500],\n    'epochs': [3, 5, 7, 9],\n    'optimizer': ['adam', 'rmsprop', 'sgd']\n}","metadata":{"execution":{"iopub.status.busy":"2024-07-01T16:51:09.846816Z","iopub.execute_input":"2024-07-01T16:51:09.847327Z","iopub.status.idle":"2024-07-01T16:51:09.854899Z","shell.execute_reply.started":"2024-07-01T16:51:09.84728Z","shell.execute_reply":"2024-07-01T16:51:09.853119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Código para encontrar los mejores hiper parámetros de la red neuronal\n# Find best hyperparameters for the DNN\n\n# Creamos modelo de kerasclassifier, usando la funcion sequential_testing ta creada / Create a keras classifier model, with the sequential_testing function\nmodel = KerasClassifier(build_fn=sequential_testing, verbose=0)\n\n# Pasamos el modelo dentro de un randomizedsearch, y la lista de los parámetros. Tomará 10 iteraciones random, diviendo nuestro espacio de trabajo en 3\n# We pass the model into a randomizedsearch, with the following parameters, we take 10 random iterations and divide our dataspace into 3\nrandom_search = RandomizedSearchCV(estimator=model, param_distributions=parameters, n_iter=10, cv=3, verbose=2, random_state=8, n_jobs=-1)\nrandom_search_result = random_search.fit(X_train, y_train)\n\n# Mostrar el historial del mejor modelo\n# We then show the best scores and parameters\nprint(f'Best Score: {random_search_result.best_score_}')\nprint(f'Best Params: {random_search_result.best_params_}')\n\n# Capturar y mostrar loss y recall del mejor modelo\n# For the best model, we will then show the loss and recall\nbest_model = random_search_result.best_estimator_.model\nhistory = best_model.history.history\nprint(f\"Training Loss: {history['loss'][-1]}\")\nprint(f\"Training Recall: {history['recall'][-1]}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T17:40:49.795699Z","iopub.execute_input":"2024-07-01T17:40:49.796433Z","iopub.status.idle":"2024-07-01T17:53:43.426839Z","shell.execute_reply.started":"2024-07-01T17:40:49.796293Z","shell.execute_reply":"2024-07-01T17:53:43.423879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Se procede a comparar distintos resultados con elementos de Machine Learning \nMachine Learning methods**","metadata":{}},{"cell_type":"code","source":"# Lista de distintos métodos de aprendizaje automatico (diccionario)\n# List of differents ML methods (dictionary)\n\nmodel_list = {\n    'Random Forest Classifier': RandomForestClassifier(),\n    'AdaBoost Classifier': AdaBoostClassifier(),\n    'Logistic Regression': LogisticRegression(),\n    'XGBoost': XGBClassifier(),\n    'Naive Bayes': GaussianNB(),\n    'Support Vector Machines': SVC(),\n}","metadata":{"execution":{"iopub.status.busy":"2024-07-01T18:02:46.996541Z","iopub.execute_input":"2024-07-01T18:02:46.997146Z","iopub.status.idle":"2024-07-01T18:02:47.005345Z","shell.execute_reply.started":"2024-07-01T18:02:46.997095Z","shell.execute_reply":"2024-07-01T18:02:47.003543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clase que correrá e iterará por cada elemento de la lista anterior\n# Class that will iterate between each ML method\n\nclass model_testing():\n    def __init__(self, model_list):\n        for model_name, initialize in model_list.items():\n            model = initialize\n            model.fit(X_train, y_train)\n            prediction = model.predict(X_test)\n            model_recall = recall_score(y_test, prediction)\n            model_loss = log_loss(y_test, prediction)\n            print(f'{model_name} loss: {model_loss}')\n            print(f'{model_name} recall: {model_recall}')\n\nresults = model_testing(model_list)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T18:17:24.825468Z","iopub.execute_input":"2024-07-01T18:17:24.82626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Crear modelo de Random Forest\nimportance_model = XGBClassifier()\n\n# Entrenar el modelo\nimportance_model.fit(X, y)\n\n# Obtener la importancia de características\nfeature_importance = importance_model.feature_importances_\n\n# Crear un DataFrame para mostrar las importancias de las características\nimportance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\n\nprint(importance_df.head(10))","metadata":{"execution":{"iopub.status.busy":"2024-07-02T23:44:59.661819Z","iopub.execute_input":"2024-07-02T23:44:59.662538Z","iopub.status.idle":"2024-07-02T23:45:44.340203Z","shell.execute_reply.started":"2024-07-02T23:44:59.662478Z","shell.execute_reply":"2024-07-02T23:45:44.338533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"La idea principal es ingresar nuevas encuestas con las preguntas de nuestros atributos, y dejar que nuestro algoritmo decida si la persona está (o debiera estar) bajo un tratamiento de salud mental. Hablé con esta actual encuesta con psicólogos y coinciden en que las encuestas que realizan, se relaciona bien con los parámetros de importancia que fueron seleccionados.\n\nCon esto, tenemos dos opciones, seleccionando en primera instancia la Red Neuronal (con los parámetros establecidos como los mejores) tanto como XGBoost, ámbos análisis se pueden usar en conjunto para un mejor resultado.\n\nThe main idea is to input new surveys with this question, and let te algorithm check if the person is currently (or should be) in a mental health process/check. I talked about this survey with actual psychologists and told me that the algorithm is calculating fine the impact of the features.\n\nWith this, we now have two options, a Deep Neuronal Network, and a ML method XGBOOST, both ways can be use un conjuction for a better result.","metadata":{}}]}